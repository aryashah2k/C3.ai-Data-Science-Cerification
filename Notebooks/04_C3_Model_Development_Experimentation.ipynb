{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Experimentation on the C3 AI Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will cover:\n",
    "- Best practices for experimenting with and tuning machine learning pipelines at scale\n",
    "- Performing hyperparameter optimization using the `MLAutoTuner`\n",
    "- Preparing a trained and tuned pipeline for production deployment as an `MLModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Machine Learning Experimentation on the C3 AI Suite](#1)\n",
    "    * [1. Import packages and Helper Functions](#1.1)\n",
    "    * [2. Create Train, Test and Validation segments](#1.3)\n",
    "    * [3. Define how to retrieve features, label, mask](#1.4)\n",
    "    * [4. Define Machine Learning Pipeline](#1.5)\n",
    "    * [5. Define Hyperparameter Search Space](#1.6)\n",
    "    * [6. Define Scoring Metric](#1.7)\n",
    "    * [7. Define the Validation Technique](#1.8)\n",
    "    * [8. Define the Hyperparameter Search Technique](#1.9)\n",
    "    * [9. Define the Execution Criteria](#1.10)\n",
    "    * [10. Put it all together in MLAutoTunerSearchSpec](#1.11)\n",
    "    * [11. Submit a MLAutoTuner search job](#1.12)\n",
    "    * [12. Score and Analyze Results](#1.13)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 1. Import the necessary packages <a class=\"anchor\" id=\"1.1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:14.824225Z",
     "start_time": "2022-04-11T13:25:14.819009Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import collections\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 2: Create Train, Test and Validation segments <a class=\"anchor\" id=\"1.3\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Determine which C3 Type you are using as the subject of your ML experiments ( = which Type your features and metrics are defined on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:14.857449Z",
     "start_time": "2022-04-11T13:25:14.825867Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subject_type_name = \"SmartBulb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we're creating our traing, validation and test segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:14.906447Z",
     "start_time": "2022-04-11T13:25:14.859276Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "training_segment = c3.MLPopulationSegment(\n",
    "    subjectFilter=\"!(contains(id, 'SMBLB1') || contains(id, 'SMBLB2'))\", # Which subjects to include in the group\n",
    "#     mlProject=project, # use this to attach your model experimentation to an existing ML Project for traceability\n",
    "    name=\"TrainingBulbs\",\n",
    ").upsert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:14.942759Z",
     "start_time": "2022-04-11T13:25:14.908075Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "validation_segment = c3.MLPopulationSegment(\n",
    "    subjectFilter=\"contains(id, 'SMBLB1')\", # Which subjects to include in the group\n",
    "#     mlProject=project, # use this to attach your model experimentation to an existing ML Project for traceability\n",
    "    name=\"ValidationBulbs\",\n",
    ").upsert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:15.004089Z",
     "start_time": "2022-04-11T13:25:14.944219Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_segment = c3.MLPopulationSegment(\n",
    "    subjectFilter=\"contains(id, 'SMBLB2')\", # Which subjects to include in the group\n",
    "#     mlProject=project, # use this to attach your model experimentation to an existing ML Project for traceability\n",
    "    name=\"TestingBulbs\",\n",
    ").upsert()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 3: Define how to retrieve features, label, mask <a class=\"anchor\" id=\"1.4\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:15.146166Z",
     "start_time": "2022-04-11T13:25:15.005664Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(c3.SmartBulb.listMetrics().toJson())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Construct an `EvalMetricsDatasetMLDataSourceSpec` which is a specification for how we wish to construct our dataset for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:15.178730Z",
     "start_time": "2022-04-11T13:25:15.147462Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# List of C3 metric (SimpleMetric or Compound) names\n",
    "features = [\n",
    "                \"AverageTemperature\",\n",
    "                \"AveragePower\",\n",
    "]\n",
    "\n",
    "# We will use this to discard data AFTER a bulb has failed\n",
    "mask = 'HasEverFailed'\n",
    "label = 'WillFailNextMonth'\n",
    "train_start_date = \"2016-01-01\" # datetime string for start of training period\n",
    "train_end_date = \"2021-01-01\" # datetime string for end of training period\n",
    "time_series_interval = \"DAY\" # string specifying interval of data (See Interval type for more info)\n",
    "\n",
    "source_spec = c3.EvalMetricsDatasetMLDataSourceSpec(\n",
    "    name=\"training_smartbulb\",\n",
    "    srcType=subject_type_name,\n",
    "    features=features,\n",
    "    maskMetric=mask,\n",
    "    target=label,\n",
    "    start=train_start_date,\n",
    "    end=train_end_date,\n",
    "    interval=time_series_interval\n",
    ").upsert()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we use the `EvalMetricsDatasetMLDataSourceSpec` defined above and generate training, validation and test datasets in a distributed fashion. These features are evaluated and persisted on the platform and the client is given a reference to these datasets. We will use the reference to the generated datasets to do the remainder of our experimentation and will not pull this dataset into our relatively memory constrained client (jupyter). \n",
    "\n",
    "This allows us to easily scale to very large datasets limited only by filesystem storage! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:16.581387Z",
     "start_time": "2022-04-11T13:25:15.181108Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "training_dataset_generation_job = source_spec.inputAndTargetDataByReference(sourceFilter=training_segment.get().subjectFilter)\n",
    "\n",
    "validation_dataset_generation_job = source_spec.inputAndTargetDataByReference(sourceFilter=validation_segment.get().subjectFilter)\n",
    "\n",
    "test_dataset_generation_job = source_spec.inputAndTargetDataByReference(sourceFilter=test_segment.get().subjectFilter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We wait until the dataset generation jobs are complete:\n",
    "\n",
    "**Note** - `fst` and `snd` represent the jobs for features and target generation respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:34.034113Z",
     "start_time": "2022-04-11T13:25:16.583213Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_dataset_generation_job.fst.waitForCompletion()\n",
    "validation_dataset_generation_job.fst.waitForCompletion()\n",
    "test_dataset_generation_job.fst.waitForCompletion()\n",
    "training_dataset_generation_job.snd.waitForCompletion()\n",
    "validation_dataset_generation_job.snd.waitForCompletion()\n",
    "test_dataset_generation_job.snd.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can easily construct the X's and y's for our supervised learning problem and get a handle to these generated datasets without pulling the data into our Jupyter client and materializing them:\n",
    "\n",
    "**Note** - We are accessing the `default` collection since we haven't declared a grouping field for our dataset generation job. We can optionally specify this grouping field and only get a handle to a dataset that is grouped by a certain field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:34.813368Z",
     "start_time": "2022-04-11T13:25:34.035314Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_dataset_ref = training_dataset_generation_job.fst.results()[\"default\"][0]\n",
    "y_train_dataset_ref = training_dataset_generation_job.snd.results()[\"default\"][0]\n",
    "\n",
    "X_val_dataset_ref = validation_dataset_generation_job.fst.results()[\"default\"][0]\n",
    "y_val_dataset_ref = validation_dataset_generation_job.snd.results()[\"default\"][0]\n",
    "\n",
    "X_test_dataset_ref = test_dataset_generation_job.fst.results()[\"default\"][0]\n",
    "y_test_dataset_ref = test_dataset_generation_job.snd.results()[\"default\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Note** the structure of the `Dataset` object. It's just a reference to the persisted features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:34.818736Z",
     "start_time": "2022-04-11T13:25:34.814772Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_dataset_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 4: Define Machine Learning Pipeline <a class=\"anchor\" id=\"1.5\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T18:14:10.442578Z",
     "start_time": "2021-11-01T18:14:10.435966Z"
    },
    "hidden": true
   },
   "source": [
    "Define the machine learning pipeline that we wish to tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:37.076678Z",
     "start_time": "2022-04-11T13:25:34.819759Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "standardScaler = c3.SklearnPipe(\n",
    "                    name=\"standardScaler\",\n",
    "                    technique=c3.SklearnTechnique(\n",
    "                        # This tells ML pipeline to import sklearn.preprocessing.StandardScaler.\n",
    "                        name=\"preprocessing.StandardScaler\",\n",
    "                        # This tells ML pipeline to call \"transform\" method on sklearn.preprocessing.StandardScaler when we invoke the C3 action process() later.\n",
    "                        processingFunctionName=\"transform\"\n",
    "                    )\n",
    "                 )\n",
    "\n",
    "\n",
    "preprocess_pipeline = c3.MLSerialPipeline(\n",
    "                        name=\"preprocessPipeline\",\n",
    "                        steps=[c3.MLStep(name=\"standardScaler\",\n",
    "                                         pipe=standardScaler),\n",
    "                              ]\n",
    ")\n",
    "\n",
    "\n",
    "classifier = c3.SklearnPipe(\n",
    "                    name=\"rfc\",\n",
    "                    technique=c3.SklearnTechnique(\n",
    "                        name=\"ensemble.RandomForestClassifier\",\n",
    "                        processingFunctionName=\"predict\",\n",
    "                    )\n",
    ")\n",
    "\n",
    "\n",
    "serialPipeline = c3.MLSerialPipeline(\n",
    "                name=\"randomForestPipeline2\",\n",
    "                steps=[c3.MLStep(name=\"preprocess\",\n",
    "                                 pipe=preprocess_pipeline),\n",
    "                       c3.MLStep(name=\"classifier\",\n",
    "                                 pipe=classifier)],\n",
    "                scoringMetrics=c3.MLScoringMetric.toScoringMetricMap(scoringMetricList=[c3.MLAccuracyMetric(), c3.MLPrecisionMetric()])\n",
    "             ).upsert()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Or retrieve a previously upserted pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:37.080129Z",
     "start_time": "2022-04-11T13:25:37.078169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # If you would like to use an MLPipeline you created earlier, e.g. in the previous module, you would fetch the\n",
    "# # id and use it here\n",
    "\n",
    "# serialPipeline = c3.MLSerialPipeline.get('unique_id_of_previously_upserted_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:37.099191Z",
     "start_time": "2022-04-11T13:25:37.081114Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "serialPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 5. Define Hyperparameter Search Space <a class=\"anchor\" id=\"1.6\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note the syntax for specifying hyperparameter space to search over:\n",
    "\n",
    "`MLStepName__hyperparameter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:37.115786Z",
     "start_time": "2022-04-11T13:25:37.100253Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hyperparam_space = {\n",
    "                        \"classifier__n_estimators\": c3.IntegerRangeParamSpace(start=500, stop=1000, stepSize=100),\n",
    "                        \"classifier__max_depth\": c3.IntegerRangeParamSpace(start=2, stop=5, stepSize=1)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 6. Define Scoring Metric <a class=\"anchor\" id=\"1.7\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define the scoring metric to be used for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:37.154678Z",
     "start_time": "2022-04-11T13:25:37.116968Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scoring_metric = c3.MLF1ScoreMetric()\n",
    "scoring_metric.category()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 7. Define the Validation Technique <a class=\"anchor\" id=\"1.8\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Types of supported cross-validation techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:37.191848Z",
     "start_time": "2022-04-11T13:25:37.155798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c3.MetadataStore.tag().typesThatMixin(\"MLValidationTechnique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will use `MLCustomHoldoutTechnique`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:25:37.197227Z",
     "start_time": "2022-04-11T13:25:37.192957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_technique = c3.MLCustomHoldoutTechnique(\n",
    "    customInputValidate=X_val_dataset_ref,\n",
    "    customTargetOutputValidate=y_val_dataset_ref,\n",
    "    validationMetric=\"f1_score\", \n",
    "    scoringMetrics={\n",
    "        \"f1_score\": scoring_metric\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 8. Define the Hyperparameter Search Technique <a class=\"anchor\" id=\"1.9\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will use a simple `Grid` search algorithm which can be parallelized across the c3 cluster. Try to find out what other algorithms we support!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:26:01.140741Z",
     "start_time": "2022-04-11T13:25:37.198311Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hyp_technique = c3.MLHyperParamSearchTechniqueChocolate(\n",
    "    algorithm=\"Grid\"\n",
    ")\n",
    "hyp_technique.isSerial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 9. Define the Execution Criteria <a class=\"anchor\" id=\"1.10\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:26:01.144555Z",
     "start_time": "2022-04-11T13:26:01.142149Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exec_spec = c3.MLHyperParamExecSpec(\n",
    "    keepAllTrainedPipes=True,\n",
    "    checkAutoEarlyStop=True,\n",
    "    targetScore=0.97\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 10. Put it all together in MLAutoTunerSearchSpec <a class=\"anchor\" id=\"1.11\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Note** - You should change the `maxIterations` field here to account for your search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:26:01.165068Z",
     "start_time": "2022-04-11T13:26:01.145711Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search_spec = c3.MLAutoTunerSearchSpec(\n",
    "    validationTechnique=val_technique,\n",
    "    hyperParamSearchTechnique=hyp_technique,\n",
    "    executionSpec=exec_spec,\n",
    "    maxConcurrentIterations=100,\n",
    "    maxIterations=1,\n",
    "    maxSearchTime=600,\n",
    "    refit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 11. Submit a MLAutoTuner search job <a class=\"anchor\" id=\"1.12\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:26:01.498288Z",
     "start_time": "2022-04-11T13:26:01.167023Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auto_tuner = c3.MLAutoTuner(name=\"MyUniqueMLAutoTunerName\").search(\n",
    "                            # mlProject=project,\n",
    "                            pipe=serialPipeline.get(),\n",
    "                            hyperparameterSpace=hyperparam_space,\n",
    "                            input=X_train_dataset_ref,\n",
    "                            targetOutput=y_train_dataset_ref,\n",
    "                            spec=search_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:26:01.520650Z",
     "start_time": "2022-04-11T13:26:01.501015Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auto_tuner.get('MyUniqueMLAutoTunerName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:31:23.828634Z",
     "start_time": "2022-04-11T13:26:01.522055Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def check_auto_tuner_status(auto_tuner):\n",
    "    import pandas as pd\n",
    "    from IPython.display import clear_output\n",
    "    clear_output()\n",
    "    if auto_tuner.get(\"completedIterations\").completedIterations is None:\n",
    "        display(f\"Status: {auto_tuner.state()}\")\n",
    "    else:\n",
    "        completed_iterations = auto_tuner.get(\"completedIterations\").completedIterations\n",
    "        results = [i[\"validationFoldsResults\"][0] for i in completed_iterations.toJson()]\n",
    "        for iteration, res in zip(completed_iterations, results):\n",
    "            res[\"HP\"] = iteration.hyperParameters.toJson()\n",
    "        df = pd.json_normalize(results)\n",
    "        df[\"timeElapsed\"] = [iteration.endTimestamp - iteration.startTimestamp for iteration in completed_iterations]\n",
    "        display(f\"Status: {auto_tuner.state()}\")\n",
    "        display(df[[col for col in df.columns if \"Scores\" in col or \"HP\" in col] + [\"timeElapsed\"]])\n",
    "        if auto_tuner.state() == \"completed\":\n",
    "            display(\"********** BEST MODEL RESULT RETRAINED ON TRAIN + VAL DATASETS **********\")\n",
    "            display(auto_tuner.bestResult())\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "while True:\n",
    "    import time\n",
    "    if check_auto_tuner_status(auto_tuner):\n",
    "        break\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:31:23.859936Z",
     "start_time": "2022-04-11T13:31:23.830300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auto_tuner.errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 12. Score and Analyze Results <a class=\"anchor\" id=\"1.13\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can retrieve the best fit model that has been retrained on both the training and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:31:24.057384Z",
     "start_time": "2022-04-11T13:31:23.861565Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "retrievedPipeline = auto_tuner.get().retrainedPipe.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:33:23.415997Z",
     "start_time": "2022-04-11T13:31:24.058980Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_score = retrievedPipeline.score(input=X_train_dataset_ref, targetOutput=y_train_dataset_ref)\n",
    "test_score = retrievedPipeline.score(input=X_test_dataset_ref, targetOutput=y_test_dataset_ref)\n",
    "print(f'train score = {train_score}')\n",
    "print(f'test score = {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can generate predictions on the platform. Note the returned predictions are c3 `Dataset`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:33:44.864456Z",
     "start_time": "2022-04-11T13:33:23.417162Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = retrievedPipeline.process(input=X_train_dataset_ref)\n",
    "y_pred_test = retrievedPipeline.process(input=X_test_dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We convert back to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:33:58.534169Z",
     "start_time": "2022-04-11T13:33:44.865715Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_train_df = c3.Dataset.toPandas(y_pred_train)\n",
    "y_pred_test_df = c3.Dataset.toPandas(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we declare a plotting method that will plot the precision and recall curve along with the average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:33:59.381849Z",
     "start_time": "2022-04-11T13:33:58.535749Z"
    },
    "code_folding": [
     4
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def plot_prec(y_pred_test, y_true_test, y_pred_train, y_true_train, fp=None, save=False):\n",
    "    \n",
    "    prec, rec, thresholds = precision_recall_curve(y_true=y_true_test, probas_pred=y_pred_test)\n",
    "    avg_prec_test = average_precision_score(y_true=y_true_test, y_score=y_pred_test) \n",
    "    lw = 1\n",
    "    plt.figure(figsize=[6, 6])\n",
    "    plt.plot(rec, prec, color='darkorange',\n",
    "         lw=lw, label='Precision-Recall curve(average precision = %0.2f), Testing' % avg_prec_test)\n",
    "    \n",
    "    prec, rec, thresholds = precision_recall_curve(y_true=y_true_train, probas_pred=y_pred_train)\n",
    "    avg_prec_train = average_precision_score(y_true=y_true_train, y_score=y_pred_train) \n",
    "    lw = 1\n",
    "    \n",
    "    plt.plot(rec, prec, color='blue',\n",
    "         lw=lw, label='Precision-Recall curve(average precision = %0.2f), Training' % avg_prec_train)\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if save:\n",
    "        plt.savefig(fp)\n",
    "    plt.show()\n",
    "    return avg_prec_test, avg_prec_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use the helper method to plot the precision recall curve for the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:34:12.231647Z",
     "start_time": "2022-04-11T13:33:59.383239Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_true_train_df = c3.Dataset.toPandas(y_train_dataset_ref)\n",
    "y_true_test_df = c3.Dataset.toPandas(y_test_dataset_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:34:12.374476Z",
     "start_time": "2022-04-11T13:34:12.232963Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_avg_prec, train_avg_prec = plot_prec(y_pred_test=y_pred_test_df,\n",
    "                                          y_true_test=y_true_test_df,\n",
    "                                          y_pred_train=y_pred_train_df,\n",
    "                                          y_true_train=y_true_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:34:12.378491Z",
     "start_time": "2022-04-11T13:34:12.375686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'Average Precision Train: {train_avg_prec}')\n",
    "print(f'Average Precision Test: {test_avg_prec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step 13. Create MLModel for Deployment <a class=\"anchor\" id=\"1.14\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, we iterate over the above steps until we're satisfied with the generalizability of our machine learning pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ocne you're satisfied with the results and you have your model acheiving a good F1 score, you can uncomment and execute the following cell to create an `MLModel` from the trained and tuned pipeline which is now ready to be deployed directly in production using the [C3 AI Model Deployment Framework ](https://developer.c3.ai/docs/7.29.0/topic/modelDeployment)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:34:12.812094Z",
     "start_time": "2022-04-11T13:34:12.379685Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ml_model = c3.MLModel.createFromPipeline(\n",
    "#     pipeline=retrievedPipeline.get(), \n",
    "#     trainingDataSourceSpec=source_spec.get(),\n",
    "#     spec=c3.MLModelCreateSpec(\n",
    "#         predictionDataSourceSpec=source_spec.get(),\n",
    "#         # mlProject=project # for the DS course, this line should stay commented out;\n",
    "#                             # you would use it to to attach your model experimentation to an existing ML Project for traceability\n",
    "#     )\n",
    "# ).upsert(spec=c3.UpsertSpec(returnInclude=\"this\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the id of your created MLModel in this cell. You will deploy it in the Capstone notebook and see how your model performs against a \"LIVE\" model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-11T13:34:12.816863Z",
     "start_time": "2022-04-11T13:34:12.813528Z"
    }
   },
   "outputs": [],
   "source": [
    "# ml_model\n",
    "\n",
    "ml_model.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "has_local_update": true,
  "is_local": true,
  "is_remote": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "last_sync_time": "2022-04-11T13:23:28.263964"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
